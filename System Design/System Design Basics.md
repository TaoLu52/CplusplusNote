## 引言：
设计大型系统需要考虑如下几个方面：
1. 建构系统时有哪些不同的构件可以使用
2. 这些组件怎样与别的组件组合成一个系统并协同工作
3. 对于不同组件如何取舍，各组件的权重如何分配
## 一、分布式系统的的关键特性
分布式系统的关键特性包括：
	1. 可扩展
	2. 可靠
	3. 有效
	4. 高效
	5. 可维护
### 可扩展
系统应该能随着需求、维护费用等的变化在不损失性能的前提下进行扩充或缩减。
#### 水平扩展与垂直扩展（Vertical Scaling vs. Horizontal Scaling）
**水平扩展**：通过往资源池添加更多服务器来实现扩展；**垂直扩展**：通过提升现有服务器的能力（使用更强的CPU，更大的存储器等）来实现扩展。
通常水平扩展比垂直扩展更容易。在水平扩展方面的范例是Cassandra 和MongoDB。而在垂直扩展方面的范例是MySQL。
垂直扩展的一个缺点是垂直扩展通常会导致系统下线维护。
![[Pasted image 20231025144218.png]]
### 可靠与有效
**可靠性**指系统能够稳定运行服务，即使在部分服务器故障时服务依然可以运行。**有效性**指系统在特定时间段内系统可以提供服务的时间。
可靠性需要通过软硬件的**冗余备份**来实现。显然冗余备份是有成本的，但是需要通过这种方式来消除各个**单点失败**。有效性关注的是系统维护、修复、空档等时间。
如果一个系统具有较高的可靠性，那这个系统就具有较高的可用性。而一个系统如果不可靠，它同样可以通过尽可能缩短维护时间等手段提高有效性。
### 高效
精准的测量系统的效率的是比较困难的，但是可以使用吞吐量等类似的指标来粗略的衡量
### 可用、可维护
我们设计的系统应该是易于操作与维护的。
快速诊断并精准定位错误，在早期发现问题都是提高这两个指标的关键。
## 二、负载均衡（Load Balancing）
### 负载均衡介绍
负载均衡是分布式系统一个很重要的组件。它可以提高系统的吞吐量并提升系统的稳定性。同时，负载均衡也担负着跟踪系统各项资源状态的任务。如果一台服务器在某一时刻无法提供服务或故障率显著提高，负载均衡可以不再将请求分给这台服务器。
负载均衡通常位于客户端和服务器之间，使用算法将各个客户端的请求分发给不同的服务器。具体拓扑如下图所示：
![[Pasted image 20231025152611.png]]
负载均衡可以避免单点失败并提高系统的可用性及相应效率。
为了实现可扩展性和冗余备份并平衡系统每一层的负载，我们可以在这三个地方加入负载均衡：
- user 与 web server间
- web server和内部platform层之间（比如application server和cache server）之间
- 在platform层和数据库之间
如下图：
![[Pasted image 20231025153645.png]]
### 负载均衡的益处
- 用户体验更快的没有中断的服务。
- 提高系统下线维护时间，提升系统吞吐量。
- 系统管理员可以更方便的分配到来的请求。
- 智能化的负载均衡可以在流量阻塞瓶颈真正发生前进行预测、分析、判断。这样可以让团队对系统有更深层次的认识，为团队商务上的判断提供支持。
### 负载均衡算法
健康检测（Health Checks ）是负载均衡算法的重要依据，负载均衡应该只向健康的服务器转发请求。
算法有：
1. 最少链接
2. 最少相应时间
3. 最少带宽占用
4. 轮询法 Round Robin Method
5. 带权轮询法 Weighted Round Robin Method
6. IP Hash
### 负载均衡备份
负载均衡容易成为系统的单点故障点，为了克服这一缺点，可以使用备用的LB Server与主LB Server相连，互相检测对方的健康状态，一旦主服务器失效，副服务器就可以启用并接管负载均衡的工作
![[Pasted image 20231025155605.png]]
## 三、缓存（ Caching ）
Cache 可以极大提升现有系统的性能。依据局部性原理（the locality of reference principle）：最近被请求的数据很可能被再次请求。在计算机系统的各个层面中都使用了cache。cache 相比与RAM，容量受限但是速度更快。Cache一般放置在离请求最近的地方，以便以更快的速度响应请求。
### 应用服务器缓存（Application server cache）
在请求层直接放置cache让本地存储回复的数据，但是在LB随机分配请求时，会导致cache miss的次数增加。解决这个问题的两个似乎是全局cache和分布式cache
### CDN ( Content Distribution Network )
CDN用来为不同地区发生的请求分配最近的服务器
### Cache Invalidation
Cache带来的一个问题是需要维护以保持数据的一致性。
如果一项数据在数据库中被修改了，那么它应该在cache中被无效化（invalidate）以免带来数据不一致。
有三种主流方法来解决这一问题：
1. Write-through cache: 在这种模式下，数据会在同一时刻写入cache和响应得数据库。
	这种模式下，cache的数据可以用来快速检索，而存在数据库中的数据保证了在掉电等异常情况下数据不会丢失。
	这种模式的弊端在于每次写操作都要在内部写两次后才能对外写成功，这会带来很大的写操作延时。
2. Write-around cache: 这种方式类似与write through。但是在这种模式下，数据会直接写入数据库，而绕过cache以提高速度。这种模式下对于刚写过的数据，在随后的读时，会产生一次 ”cache miss“，数据读取时只能从数据库中读，会产生高延迟。
3. Write-back cache: 在这种方式下，数据只会写入cache。并且对外立刻确认写成功。而在一段特定的间隔或在特定条件下再写入数据库。这种模式下写入延迟较低，对于写密集的应用程序的速度提升较大。但是这种模式下会带来特定情况（宕机，掉电）下的数据丢失。
### Cache eviction policies
Cache退出的策略：
1. FIFO(First In First Out): Cache 会先让最先进入Cache的条目，不管这一条目的使用的频率。
2. LIFO(Last In First Out): Cache会先让最后进入的先退出。
3. LRU(Least Recently Used): 抛弃最早使用的条目
4. MRU(Most Recently Used): 抛弃最近使用的条目
5. LFU(Least Frequently Used): 抛弃最少使用的条目
6. RR(Random Replacement): 随机选择一个条目抛弃

## 四、数据分区（Sharding or Data Partitioning）
分区与分片
### 1. 数据分区和扩展有两种方式：
	1. 水平分区
		以特定条件将数据放在不同的表中。这种方式需要仔细的选择分表的条件，条件不合适的时候，会造成各个表中数据分布不均匀。
	2. 垂直分区
		将同一条目中的不同项放在不同表中。这种方式的问题是当未来业务增长后，需要重新分区。
	3. Directory Based Partitioning
		这种方式会建立一个查询服务，这个服务可以解耦数据库的具体实现。
		这个查询服务会掌握数据库的具体mapping
### 2. 分区条件：
	1. Key or Hash-based partitioning
		使用Hash函数，基于数据的特定属性来分表
	2. List partitioning
		每张表被分配一张列表，当插入新的数据时，查询数据的属性在哪一张的列表中
	3. Round-robin partitioning
		使用取模之类的方式直接分区
	4. Composite partitioning
		综合方式。综合上面的多种方式来分区
### 3. 数据分区的一般性问题
	1. Joins and Denormalization
	2. Referential integrity
	3. Rebalancing    

## 五、索引
索引可以提升检索的效率，但是由于索引本身的空间占用会减慢写的速度。
## 六、代理（Proxies）
Proxy 服务器是一个在客户端和后端间的中转服务器。
通常来说，Proxies用来过滤请求，做log或者转换请求（加头尾，加解密，压缩）。
Proxy的另外一个好处是它的Cache可以用来回复很多的请求。
![[Pasted image 20231027155934.png]]
### Proxy的类型
1. 开放式代理：允许任何用户访问服务
	1. 匿名代理：会隐藏使用者IP
	2. 透明代理：会透传使用者IP
2. 反向代理：反向代理会代理服务器接受客户端的请求，并去在不同的服务器检索资源，并将检索到的资源返回客户端。从客户端角度看就像是客户端是直接请求Proxy的一样。是真实的服务端对客户端不可见
3. 正向代理：类似于VPN。客户端指定代理服务器，由代理服务器向真正的服务端发出请求
反向代理代理的是服务器，Proxy充当服务器的角色。而正向代理代理的是客户端，Proxy替客户端发送请求

## 思维导图
![[SysDesignMind.canvas]]
## 引言：
设计大型系统需要考虑如下几个方面：
1. 建构系统时有哪些不同的构件可以使用
2. 这些组件怎样与别的组件组合成一个系统并协同工作
3. 对于不同组件如何取舍，各组件的权重如何分配
## 一、分布式系统的的关键特性
分布式系统的关键特性包括：
	1. 可扩展
	2. 可靠
	3. 有效
	4. 高效
	5. 可维护
### 可扩展
系统应该能随着需求、维护费用等的变化在不损失性能的前提下进行扩充或缩减。
#### 水平扩展与垂直扩展（Vertical Scaling vs. Horizontal Scaling）
**水平扩展**：通过往资源池添加更多服务器来实现扩展；**垂直扩展**：通过提升现有服务器的能力（使用更强的CPU，更大的存储器等）来实现扩展。
通常水平扩展比垂直扩展更容易。在水平扩展方面的范例是Cassandra 和MongoDB。而在垂直扩展方面的范例是MySQL。
垂直扩展的一个缺点是垂直扩展通常会导致系统下线维护。
![[Pasted image 20231025144218.png]]
### 可靠与有效
**可靠性**指系统能够稳定运行服务，即使在部分服务器故障时服务依然可以运行。**有效性**指系统在特定时间段内系统可以提供服务的时间。
可靠性需要通过软硬件的**冗余备份**来实现。显然冗余备份是有成本的，但是需要通过这种方式来消除各个**单点失败**。有效性关注的是系统维护、修复、空档等时间。
如果一个系统具有较高的可靠性，那这个系统就具有较高的可用性。而一个系统如果不可靠，它同样可以通过尽可能缩短维护时间等手段提高有效性。
### 高效
精准的测量系统的效率的是比较困难的，但是可以使用吞吐量等类似的指标来粗略的衡量
### 可用、可维护
我们设计的系统应该是易于操作与维护的。
快速诊断并精准定位错误，在早期发现问题都是提高这两个指标的关键。
## 二、负载均衡（Load Balancing）
### 负载均衡介绍
负载均衡是分布式系统一个很重要的组件。它可以提高系统的吞吐量并提升系统的稳定性。同时，负载均衡也担负着跟踪系统各项资源状态的任务。如果一台服务器在某一时刻无法提供服务或故障率显著提高，负载均衡可以不再将请求分给这台服务器。
负载均衡通常位于客户端和服务器之间，使用算法将各个客户端的请求分发给不同的服务器。具体拓扑如下图所示：
![[Pasted image 20231025152611.png]]
负载均衡可以避免单点失败并提高系统的可用性及相应效率。
为了实现可扩展性和冗余备份并平衡系统每一层的负载，我们可以在这三个地方加入负载均衡：
- user 与 web server间
- web server和内部platform层之间（比如application server和cache server）之间
- 在platform层和数据库之间
如下图：
![[Pasted image 20231025153645.png]]
### 负载均衡的益处
- 用户体验更快的没有中断的服务。
- 提高系统下线维护时间，提升系统吞吐量。
- 系统管理员可以更方便的分配到来的请求。
- 智能化的负载均衡可以在流量阻塞瓶颈真正发生前进行预测、分析、判断。这样可以让团队对系统有更深层次的认识，为团队商务上的判断提供支持。
### 负载均衡算法
健康检测（Health Checks ）是负载均衡算法的重要依据，负载均衡应该只向健康的服务器转发请求。
算法有：
1. 最少链接
2. 最少相应时间
3. 最少带宽占用
4. 轮询法 Round Robin Method
5. 带权轮询法 Weighted Round Robin Method
6. IP Hash
### 负载均衡备份
负载均衡容易成为系统的单点故障点，为了克服这一缺点，可以使用备用的LB Server与主LB Server相连，互相检测对方的健康状态，一旦主服务器失效，副服务器就可以启用并接管负载均衡的工作
![[Pasted image 20231025155605.png]]
## 三、缓存（ Caching ）
Cache 可以极大提升现有系统的性能。依据局部性原理（the locality of reference principle）：最近被请求的数据很可能被再次请求。在计算机系统的各个层面中都使用了cache。cache 相比与RAM，容量受限但是速度更快。Cache一般放置在离请求最近的地方，以便以更快的速度响应请求。
### 应用服务器缓存（Application server cache）
在请求层直接放置cache让本地存储回复的数据，但是在LB随机分配请求时，会导致cache miss的次数增加。解决这个问题的两个似乎是全局cache和分布式cache
### CDN ( Content Distribution Network )
CDN用来为不同地区发生的请求分配最近的服务器
### Cache Invalidation
Cache带来的一个问题是需要维护以保持数据的一致性。
如果一项数据在数据库中被修改了，那么它应该在cache中被无效化（invalidate）以免带来数据不一致。
有三种主流方法来解决这一问题：
1. Write-through cache: 在这种模式下，数据会在同一时刻写入cache和响应得数据库。
	这种模式下，cache的数据可以用来快速检索，而存在数据库中的数据保证了在掉电等异常情况下数据不会丢失。
	这种模式的弊端在于每次写操作都要在内部写两次后才能对外写成功，这会带来很大的写操作延时。
2. Write-around cache: 这种方式类似与write through。但是在这种模式下，数据会直接写入数据库，而绕过cache以提高速度。这种模式下对于刚写过的数据，在随后的读时，会产生一次 ”cache miss“，数据读取时只能从数据库中读，会产生高延迟。
3. Write-back cache: 在这种方式下，数据只会写入cache。并且对外立刻确认写成功。而在一段特定的间隔或在特定条件下再写入数据库。这种模式下写入延迟较低，对于写密集的应用程序的速度提升较大。但是这种模式下会带来特定情况（宕机，掉电）下的数据丢失。
### Cache eviction policies
Cache退出的策略：
1. FIFO(First In First Out): Cache 会先让最先进入Cache的条目，不管这一条目的使用的频率。
2. LIFO(Last In First Out): Cache会先让最后进入的先退出。
3. LRU(Least Recently Used): 抛弃最早使用的条目
4. MRU(Most Recently Used): 抛弃最近使用的条目
5. LFU(Least Frequently Used): 抛弃最少使用的条目
6. RR(Random Replacement): 随机选择一个条目抛弃

## 四、数据分区（Sharding or Data Partitioning）
分区与分片
### 1. 数据分区和扩展有两种方式：
	1. 水平分区
		以特定条件将数据放在不同的表中。这种方式需要仔细的选择分表的条件，条件不合适的时候，会造成各个表中数据分布不均匀。
	2. 垂直分区
		将同一条目中的不同项放在不同表中。这种方式的问题是当未来业务增长后，需要重新分区。
	3. Directory Based Partitioning
		这种方式会建立一个查询服务，这个服务可以解耦数据库的具体实现。
		这个查询服务会掌握数据库的具体mapping
### 2. 分区条件：
	1. Key or Hash-based partitioning
		使用Hash函数，基于数据的特定属性来分表
	2. List partitioning
		每张表被分配一张列表，当插入新的数据时，查询数据的属性在哪一张的列表中
	3. Round-robin partitioning
		使用取模之类的方式直接分区
	4. Composite partitioning
		综合方式。综合上面的多种方式来分区
### 3. 数据分区的一般性问题
	1. Joins and Denormalization
	2. Referential integrity
	3. Rebalancing    

## 五、索引
索引可以提升检索的效率，但是由于索引本身的空间占用会减慢写的速度。
## 六、代理（Proxies）
Proxy 服务器是一个在客户端和后端间的中转服务器。
通常来说，Proxies用来过滤请求，做log或者转换请求（加头尾，加解密，压缩）。
Proxy的另外一个好处是它的Cache可以用来回复很多的请求。
![[Pasted image 20231027155934.png]]
### Proxy的类型
1. 开放式代理：允许任何用户访问服务
	1. 匿名代理：会隐藏使用者IP
	2. 透明代理：会透传使用者IP
2. 反向代理：反向代理会代理服务器接受客户端的请求，并去在不同的服务器检索资源，并将检索到的资源返回客户端。从客户端角度看就像是客户端是直接请求Proxy的一样。是真实的服务端对客户端不可见
3. 正向代理：类似于VPN。客户端指定代理服务器，由代理服务器向真正的服务端发出请求
反向代理代理的是服务器，Proxy充当服务器的角色。而正向代理代理的是客户端，Proxy替客户端发送请求

## 七、冗余与备份
### 冗余
冗余是系统关键组件或者功能的副本以提高系统的可靠。冗余是消除系统单点失败的重要策略。
### 备份
备份意味着分享信息保证数据的一致性。在数据库管理系统（DBMS）中被广泛使用。主机在获取了所有更新后再推送给所有的从机。每台从机输出确认收到更新的消息以便接收之后的更新。
## 八、SQL 与 NoSQL
数据库主要有两类：关系型数据库SQL 与 非关系型数据库NoSQL 。关系型数据库是结构化的，预先定义好结构蓝图。非关系型数据库分散的，非结构化的，结构动态变化的。
### SQL
关系型数据库以行、列的方式存储数据。每一行存储一个条目，每一列存储独立的一项数据。关系型数据库有：MySQL, Oracle, MS SQL Server, SQLite, Postgres, and MariaDB.
### NoSQL
#### Key-Value 数据库：
数据库以键值对的形式存储数据。最有名的KV 数据库包括：Redis, Voldemort, and Dynamo.
#### 文件型数据库：
数据被从在文件中，而文件被分组。每个文件的结构会完全不同。包括：CouchDB and MongoDB。
#### Wide-Column Databases：
不常见，暂时不写
#### Graph Databases:
不常见，暂时不写
### SQL 与 NoSQL 的顶层不同。
#### 存储方式：
SQL 以表的方式存储数据。
NoSQL 有不同的数据存储模型。主要有KV型的，文件型的，图型的和宽列的。
#### Schema结构:
在SQL中，每个记录都有一个固定的结构，意味着每一列都要事先定义好。
在NoSQL中，结构是动态变化的。
#### 查询方式：
SQL数据库使用SQL语言来操作数据库。
NoSQL使用unQL（Unstructured Query Language）不同的NoSQL用的语言不一样。
#### 扩展性：
SQL数据库易于做垂直扩展，水平扩展不方便。
NoSQL数据库易于做水平扩展。
#### 可靠性及ACID（Atomicity, Consistency, Isolation, Durability）
大部分关系型数据库在ACID指标方面表现更优异。
而大部分NoSQL方案都在ACID方面做了一定的牺牲来提高扩展性和运行性能。
### SQL 与NoSQL的选择策略
#### 使用SQL的原因：
1. 需要确保ACID原则。
2. 数据是结构化的，结构不会发送变化。业务量比较稳定，不会有快速扩大的风险。
#### 使用NoSQL的原因：
需要快速响应，数据不能成为系统瓶颈时通常使用NoSQL（例如大数据类型的应用）
1. 存储大量非结构化数据时
2. 云计算，云存储
3. 业务快速变化

## 九、CAP定理
![[Pasted image 20231101172545.png]]
	该理论的内容是：在设计分布式系统时，需要在CAP三项指标中有做取舍。对于分布式系统，我们只能在CAP中选择其中的两项：
	1. Consistency：一致性。所有节点在同一时间看到的数据是一样的。通过在读之前更新节点来实现。
	2. Availability： 可用性。响应每一个请求（成功或者失败）。通过在不同的服务器保存数据副本来实现。
	3. Partition tolerance：稳定性（容错性）。系统可以在信息丢失或部分组件失效的情况下继续工作。高容错性的系统可以在网络情况差，存在大量网络通信失败的情况下工作。数据在各个节点间被充分备份以便在各种间断中维持系统。
***我们建立的系统不可能同时符合CAP三原则。只能兼顾其中的两项。***
比如：为了数据一致性，所有的节点都要在同一时间得到同一数据存放节点的更新，但是如果这个时候网络出错，更新就可能不会及时的传递到所有节点。为解决这个问题，我们唯一可以做的就是暂时不要响应那些过失数据相关的请求。而这样做就不是100%可用的。
## 十、一致性哈希（Consistent Hashing）
分布式哈希表（DHT）是分布式可扩展系统的基础组件之一。哈希表需要一个Key还有一个Value。而哈希函数会建立Key和Value之间的映射。
![[Pasted image 20231102104028.png]]
但是在分布式系统中，简单的hash映射无法满足扩展要求。同时也无法做到负载均衡。在这种情况下，一致性Hash是一个很好的方式。
### 一致性哈希是什么
一致性哈希可以帮助我们在一簇设备中以最小的代价来增加或者减少节点。通过这种方式，缓存系统可以更方便的扩大或减小规模。
在一致性哈希中，当哈希表调整时，只有'k/n'个key需要重新映射。（k是key的总个数，n是服务器的总个数）。
在一致性hash中，对象优先被映射到相同的主机，但是当一台主机从系统中被移除后，该主机上的对象会被分给其他的主机；当系统中加入新的主机时，会接管一部分现有主机的映射。
### 一致性哈希是怎么工作的
![[Pasted image 20231102160404.png]]
假设目前总共有四台服务器，将他们标为1，2，3，4并组成一个环。对于任意数据，通过hash Key。得到的Hash value顺时针找到最接近的服务器编号。就是这个数据要存的服务器编号。假设2号服务器下线，那么只需要将以前存在2号服务器的数据存在3号。而假设再加入一台服务器，只需要将原来4号服务器的数据一部分分到新的5号服务器就可以。
这样做有可能导致负载不均衡，为了解决负载均衡的问题，可以使用虚拟备份的方式，某些服务器可以有多个编号。
## 十一、Long-polling（长轮询）、 Web Sockets、 Server-Sent Events
标准的HTTP请求流程：
![[Pasted image 20231102170352.png]]
### Ajax Polling
Polling轮询是AJAX中的标准技术。基本思想是：客户端重复询问（请求）服务器。如果服务器端没有数据，返回一个空的回复。
![[Pasted image 20231102172259.png]]
这种方式的问题是客户端需要不停的询问服务器是不是有新数据。这样会造成大量的空应答，导致HTTP过载。
![[Pasted image 20231102172612.png]]
### HTTP Long-Polling
HTTP 长轮询是一种传统轮询技术的变种，允许server向客户端推送消息。在长轮询下，客户端还是会像普通轮询一样向服务器发送请求，但是由于服务端有可能无法立即应答，这项技术使用”Hanging GET“：
1. 如果服务器端没有客户端想要的数据，服务器端不会立马回复空应答而是保持这个请求并等待知道有数据可用。
2. 一旦有数据准备好后，向客户端发送完整的应答。客户端之后会立即重新向服务器请求数据以便服务器端可以在有数据准备好后立即发送应答。
![[Pasted image 20231103103634.png]]
### WebSockets
WebSocket 提供了基于单一TCP链接的全双工通信通道。它提供了持久的CS链接，两端随时都可以发送数据。客户端通过WebSocket handshake的进程建立WebSocket链接。如果链接建立成功，CS两端可以直接交换数据。
### Server-Sent Events(SSEs)
在SSEs下，客户端与服务器端建立一个长期的持久链接。Server利用这个链接向客户端发送数据。如果客户端想向服务器发送数据，需要使用别的协议完成。
具体流程如下：
1. 客户端使用普通的HTTP协议向服务器端请求数据。
2. 请求的网页会打开一个与服务器端的链接。
3. 只要有新的数据就绪，server就向client发送新数据。
